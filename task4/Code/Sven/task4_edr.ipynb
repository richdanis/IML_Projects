{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task4_edr.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPV/ZIs1iqDMeMCCkzWljh8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YL4WHi0jiFhy","executionInfo":{"status":"ok","timestamp":1652864747522,"user_tz":-120,"elapsed":6282,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn as nn\n","import torch\n","import time"]},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","torch.backends.cudnn.benchmark = True"],"metadata":{"id":"Cx6P119ZiNBq","executionInfo":{"status":"ok","timestamp":1652864748870,"user_tz":-120,"elapsed":321,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# mount drive to access data\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUapcKyKiNI2","executionInfo":{"status":"ok","timestamp":1652864768193,"user_tz":-120,"elapsed":17910,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}},"outputId":"03d7f80c-9e24-47ca-87f0-919e05bf6a86"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from zipfile import ZipFile\n","with ZipFile('drive/MyDrive/Data.zip','r') as zipObj:\n","  zipObj.extractall('.')"],"metadata":{"id":"FHZ3_dJciNQS","executionInfo":{"status":"ok","timestamp":1652864772422,"user_tz":-120,"elapsed":2396,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class TrainDataset(Dataset):\n","\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","    def __getitem__(self, idx):\n","        feature = torch.from_numpy(self.data[idx]).float()\n","        return feature"],"metadata":{"id":"ZDR2sErli2FK","executionInfo":{"status":"ok","timestamp":1652864773624,"user_tz":-120,"elapsed":320,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_loaders(dataset, batch_size=64, shuffle=True, split = 0.8):\n","    \n","    assert 0 <= split <= 1\n","    \n","    features = pd.read_csv(\"Data/\" + dataset + \"_features.csv\")\n","    features = features.drop(columns=['Id', 'smiles'])\n","    features = features.to_numpy()\n","\n","    labels = pd.read_csv(\"Data/\" + dataset + \"_labels.csv\")\n","    labels = labels.drop(columns=['Id'])\n","    labels = labels.to_numpy()\n","\n","    combined = np.hstack((features, labels))\n","\n","    if shuffle:\n","        np.random.shuffle(combined)\n","\n","    split = int(split * combined.shape[0])\n","\n","    train = combined[:split]\n","    val = combined[split:]\n","\n","    print(train.shape[0])\n","    print(val.shape[0])\n","\n","    #full_dataset = TrainDataset(combined)\n","    train_dataset = TrainDataset(train)\n","    validation_dataset = TrainDataset(val)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)\n","    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)\n","    #full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0, pin_memory=True)\n","\n","    return train_loader, val_loader#, full_loader"],"metadata":{"id":"XtkDbIlZixct","executionInfo":{"status":"ok","timestamp":1652864775283,"user_tz":-120,"elapsed":366,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pretrain_loader, preval_loader = get_loaders(dataset=\"pretrain\",split = 0.9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADcVuNXLiNk0","executionInfo":{"status":"ok","timestamp":1652864794822,"user_tz":-120,"elapsed":16631,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}},"outputId":"23be5fb3-f8c1-4f62-fc64-18fd76480773"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["45000\n","5000\n"]}]},{"cell_type":"code","source":["def evaluate(model, loss_fn, val_loader, device):\n","    # goes through the test dataset and computes the test accuracy\n","    val_loss_cum = 0.0\n","    val_loss_reg = 0.0\n","    val_loss_dec = 0.0\n","    # bring the models into eval mode\n","    model.eval()\n","    y_batch_val = None\n","\n","    with torch.no_grad():\n","        num_eval_samples = 0\n","        for x_batch_val in val_loader:\n","\n","            y_batch_val = x_batch_val[:, -1]\n","            y_batch_val = torch.reshape(y_batch_val, (y_batch_val.shape[0], 1))\n","            y_batch_val = y_batch_val.to(device)\n","\n","            x_batch_val = x_batch_val[:, :-1].to(device)\n","            x_val = x_batch_val\n","\n","            x_val = model.forward_enc(x_val)\n","            x_reg = model.forward_reg(x_val)\n","            x_dec = model.forward_dec(x_val)\n","\n","            loss_reg = loss_fn(x_reg, y_batch_val)\n","            loss_dec = loss_fn(x_dec, x_batch_val)\n","            loss = loss_reg + loss_dec            \n","\n","            num_samples_batch = x_batch_val.shape[0]\n","            num_eval_samples += num_samples_batch\n","            val_loss_cum += loss * num_samples_batch\n","            val_loss_reg += loss_reg * num_samples_batch\n","            val_loss_dec += loss_dec * num_samples_batch\n","\n","        avg_val_loss = val_loss_cum / num_eval_samples\n","        avg_val_reg = val_loss_reg / num_eval_samples\n","        avg_val_dec = val_loss_dec / num_eval_samples\n","\n","        return avg_val_loss, avg_val_reg, avg_val_dec\n"],"metadata":{"id":"HrEmScnWiNd8","executionInfo":{"status":"ok","timestamp":1652864797076,"user_tz":-120,"elapsed":204,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class MolecularNet(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Linear(1000, 800),\n","            nn.LeakyReLU(),\n","            nn.Linear(800, 512),\n","            nn.LeakyReLU(),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(),\n","            nn.Linear(256, 128),\n","            #nn.LeakyReLU(),\n","            #nn.Linear(128, 64),\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            #nn.Linear(64, 128),\n","            #nn.LeakyReLU(),\n","            nn.Linear(128, 256),\n","            nn.LeakyReLU(),\n","            nn.Linear(256, 512),\n","            nn.LeakyReLU(),\n","            nn.Linear(512, 700),\n","            nn.LeakyReLU(),\n","            nn.Linear(700, 1000),\n","        )\n","\n","        self.regressor =  nn.Sequential(\n","            nn.Linear(128, 64),\n","            nn.Dropout(p=0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(64,64),\n","            nn.LeakyReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(64,32),\n","            nn.LeakyReLU(),\n","            nn.Linear(32,32),\n","            nn.LeakyReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(32,1)\n","        )\n","\n","    def forward_enc(self, x):\n","        x = self.encoder(x)\n","        return x\n","\n","    def forward_dec(self, x):\n","        x = self.decoder(x)\n","        return x\n","\n","    def forward_reg(self, x):\n","        x = self.regressor(x)\n","        return x\n","\n","moc = MolecularNet().to(device)"],"metadata":{"id":"r5oDC3YWiNXJ","executionInfo":{"status":"ok","timestamp":1652864811154,"user_tz":-120,"elapsed":11694,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.MSELoss()\n","optim = torch.optim.Adam(moc.parameters(), lr=1e-3)"],"metadata":{"id":"xjoztzJHiNrj","executionInfo":{"status":"ok","timestamp":1652864818360,"user_tz":-120,"elapsed":194,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_loop(model, train_loader, val_loader, loss_fn, optim, device, show=1, save=40, epochs=200):\n","    line = False\n","    print(f'Start training model')\n","    best_round = 0\n","    INF = 10e9\n","    cur_low_val_eval = INF\n","    for epoch in range(1,epochs+1):\n","        # reset statistics trackers\n","        train_loss_cum = 0.0\n","        train_loss_reg = 0.0\n","        train_loss_dec = 0.0\n","        num_samples_epoch = 0\n","        y_batch = None\n","        t = time.time()\n","        # Go once through the training dataset (-> epoch)\n","\n","        for x_batch in train_loader:\n","\n","            y_batch = x_batch[:, -1]\n","            y_batch = torch.reshape(y_batch, (y_batch.shape[0], 1))\n","            y_batch = y_batch.to(device)\n","\n","            # move data to GPU\n","            x_batch = x_batch[:, :-1]\n","            x_batch = x_batch.to(device)\n","\n","            # zero grads and put model into train mode\n","            optim.zero_grad()\n","            model.train()\n","\n","            # forward pass though the encoder\n","            x_enc = model.forward_enc(x_batch)\n","\n","            # forward pass though the encoder\n","            x_reg = model.forward_reg(x_enc)\n","\n","            # forward pass though the encoder\n","            x_hat = model.forward_dec(x_enc)\n","\n","            # loss\n","            loss_reg = loss_fn(x_reg, y_batch)\n","            loss_dec = loss_fn(x_hat, x_batch)\n","            loss = loss_reg + loss_dec\n","\n","            # backward pass and gradient step\n","            loss.backward()\n","            optim.step()\n","\n","            # keep track of train stats\n","            num_samples_batch = x_batch.shape[0]\n","            num_samples_epoch += num_samples_batch\n","            train_loss_reg += loss_reg * num_samples_batch\n","            train_loss_dec += loss_dec * num_samples_batch\n","            train_loss_cum += loss * num_samples_batch\n","\n","\n","        # average the accumulated statistics\n","        avg_train_reg = train_loss_reg / num_samples_epoch\n","        avg_train_reg = torch.sqrt(avg_train_reg)\n","        avg_train_dec = train_loss_dec / num_samples_epoch\n","        avg_train_dec = torch.sqrt(avg_train_dec)\n","        avg_train_loss = train_loss_cum / num_samples_epoch\n","        avg_train_loss = torch.sqrt(avg_train_loss)\n","\n","        val_loss, val_reg, val_dec = evaluate(model, loss_fn, val_loader, device)\n","        val_loss = torch.sqrt(val_loss)\n","        val_reg = torch.sqrt(val_reg)\n","        val_dec = torch.sqrt(val_dec)\n","        epoch_duration = time.time() - t\n","\n","        # print some infos\n","        if epoch % show == 0:\n","            line = True \n","            print(f'Epoch {epoch} | Duration {epoch_duration:.2f} sec')\n","            print(f'Train:      Full loss: {avg_train_loss:.4f} | Regression: {avg_train_reg:.4f} | Decoder: {avg_train_dec:.4f}')\n","            print(f'Validation: Full loss: {val_loss:.4f} | Regression: {val_reg:.4f} | Decoder: {val_dec:.4f}')\n","\n","        # save checkpoint of model\n","        if epoch % save == 0  and epoch > 2:\n","            line = True\n","            save_path = f'model_epoch_{epoch}.pt'\n","            torch.save(model, save_path)\n","            print(f'Saved model checkpoint to {save_path}')\n","\n","        if cur_low_val_eval > val_loss and epoch > 2:\n","            cur_low_val_eval = val_loss\n","            best_round = epoch\n","            save_path = f'model_best.pt'\n","            torch.save(model, save_path)\n","            #print(f'Saved model best in epoch {epoch} to checkpoint {save_path}')\n","\n","        if line:\n","            print()\n","            line = False\n","\n","    print(f'Lowess validation loss: {cur_low_val_eval:.4f} in Round {best_round}')"],"metadata":{"id":"bsTlZiTuiN4k","executionInfo":{"status":"ok","timestamp":1652864820618,"user_tz":-120,"elapsed":285,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_loop(moc, pretrain_loader, preval_loader, loss_fn, optim, device, show=2, save=10, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3hoVHSZjQnw","executionInfo":{"status":"ok","timestamp":1652865565929,"user_tz":-120,"elapsed":727499,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}},"outputId":"cb40becd-4e64-4f28-f5a0-7e1356d29913"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Start training model\n","Epoch 2 | Duration 7.05 sec\n","Train:      Full loss: 0.4470 | Regression: 0.4087 | Decoder: 0.1812\n","Validation: Full loss: 0.7495 | Regression: 0.7274 | Decoder: 0.1807\n","\n","Epoch 4 | Duration 7.12 sec\n","Train:      Full loss: 0.3443 | Regression: 0.2960 | Decoder: 0.1758\n","Validation: Full loss: 0.3997 | Regression: 0.3599 | Decoder: 0.1738\n","\n","Epoch 6 | Duration 7.00 sec\n","Train:      Full loss: 0.2958 | Regression: 0.2456 | Decoder: 0.1649\n","Validation: Full loss: 0.3159 | Regression: 0.2710 | Decoder: 0.1623\n","\n","Epoch 8 | Duration 6.92 sec\n","Train:      Full loss: 0.2525 | Regression: 0.1991 | Decoder: 0.1553\n","Validation: Full loss: 0.2125 | Regression: 0.1479 | Decoder: 0.1525\n","\n","Epoch 10 | Duration 7.22 sec\n","Train:      Full loss: 0.2135 | Regression: 0.1567 | Decoder: 0.1449\n","Validation: Full loss: 0.2233 | Regression: 0.1713 | Decoder: 0.1432\n","Saved model checkpoint to model_epoch_10.pt\n","\n","Epoch 12 | Duration 7.33 sec\n","Train:      Full loss: 0.1846 | Regression: 0.1264 | Decoder: 0.1345\n","Validation: Full loss: 0.2033 | Regression: 0.1509 | Decoder: 0.1362\n","\n","Epoch 14 | Duration 7.35 sec\n","Train:      Full loss: 0.1624 | Regression: 0.1034 | Decoder: 0.1253\n","Validation: Full loss: 0.1682 | Regression: 0.1120 | Decoder: 0.1254\n","\n","Epoch 16 | Duration 7.31 sec\n","Train:      Full loss: 0.1499 | Regression: 0.0926 | Decoder: 0.1179\n","Validation: Full loss: 0.1571 | Regression: 0.1040 | Decoder: 0.1178\n","\n","Epoch 18 | Duration 7.28 sec\n","Train:      Full loss: 0.1413 | Regression: 0.0878 | Decoder: 0.1107\n","Validation: Full loss: 0.1588 | Regression: 0.1126 | Decoder: 0.1120\n","\n","Epoch 20 | Duration 7.34 sec\n","Train:      Full loss: 0.1352 | Regression: 0.0853 | Decoder: 0.1048\n","Validation: Full loss: 0.1583 | Regression: 0.1173 | Decoder: 0.1063\n","Saved model checkpoint to model_epoch_20.pt\n","\n","Epoch 22 | Duration 7.35 sec\n","Train:      Full loss: 0.1281 | Regression: 0.0806 | Decoder: 0.0995\n","Validation: Full loss: 0.1452 | Regression: 0.1037 | Decoder: 0.1016\n","\n","Epoch 24 | Duration 7.30 sec\n","Train:      Full loss: 0.1238 | Regression: 0.0792 | Decoder: 0.0952\n","Validation: Full loss: 0.1409 | Regression: 0.1025 | Decoder: 0.0967\n","\n","Epoch 26 | Duration 7.29 sec\n","Train:      Full loss: 0.1160 | Regression: 0.0719 | Decoder: 0.0910\n","Validation: Full loss: 0.1413 | Regression: 0.1061 | Decoder: 0.0932\n","\n","Epoch 28 | Duration 7.37 sec\n","Train:      Full loss: 0.1120 | Regression: 0.0702 | Decoder: 0.0872\n","Validation: Full loss: 0.1398 | Regression: 0.1054 | Decoder: 0.0918\n","\n","Epoch 30 | Duration 7.37 sec\n","Train:      Full loss: 0.1076 | Regression: 0.0672 | Decoder: 0.0840\n","Validation: Full loss: 0.1260 | Regression: 0.0914 | Decoder: 0.0868\n","Saved model checkpoint to model_epoch_30.pt\n","\n","Epoch 32 | Duration 7.30 sec\n","Train:      Full loss: 0.1055 | Regression: 0.0665 | Decoder: 0.0819\n","Validation: Full loss: 0.1384 | Regression: 0.1088 | Decoder: 0.0854\n","\n","Epoch 34 | Duration 7.24 sec\n","Train:      Full loss: 0.1026 | Regression: 0.0648 | Decoder: 0.0795\n","Validation: Full loss: 0.1311 | Regression: 0.1004 | Decoder: 0.0842\n","\n","Epoch 36 | Duration 7.26 sec\n","Train:      Full loss: 0.0998 | Regression: 0.0628 | Decoder: 0.0775\n","Validation: Full loss: 0.1354 | Regression: 0.1088 | Decoder: 0.0807\n","\n","Epoch 38 | Duration 7.26 sec\n","Train:      Full loss: 0.0974 | Regression: 0.0619 | Decoder: 0.0751\n","Validation: Full loss: 0.1295 | Regression: 0.1022 | Decoder: 0.0795\n","\n","Epoch 40 | Duration 7.19 sec\n","Train:      Full loss: 0.0963 | Regression: 0.0619 | Decoder: 0.0738\n","Validation: Full loss: 0.1412 | Regression: 0.1175 | Decoder: 0.0784\n","Saved model checkpoint to model_epoch_40.pt\n","\n","Epoch 42 | Duration 7.28 sec\n","Train:      Full loss: 0.0934 | Regression: 0.0593 | Decoder: 0.0721\n","Validation: Full loss: 0.1307 | Regression: 0.1062 | Decoder: 0.0762\n","\n","Epoch 44 | Duration 7.31 sec\n","Train:      Full loss: 0.0923 | Regression: 0.0590 | Decoder: 0.0710\n","Validation: Full loss: 0.1293 | Regression: 0.1056 | Decoder: 0.0747\n","\n","Epoch 46 | Duration 7.33 sec\n","Train:      Full loss: 0.0906 | Regression: 0.0578 | Decoder: 0.0698\n","Validation: Full loss: 0.1171 | Regression: 0.0902 | Decoder: 0.0747\n","\n","Epoch 48 | Duration 7.23 sec\n","Train:      Full loss: 0.0892 | Regression: 0.0564 | Decoder: 0.0690\n","Validation: Full loss: 0.1264 | Regression: 0.1027 | Decoder: 0.0737\n","\n","Epoch 50 | Duration 7.26 sec\n","Train:      Full loss: 0.0879 | Regression: 0.0559 | Decoder: 0.0678\n","Validation: Full loss: 0.1182 | Regression: 0.0927 | Decoder: 0.0733\n","Saved model checkpoint to model_epoch_50.pt\n","\n","Epoch 52 | Duration 7.22 sec\n","Train:      Full loss: 0.0875 | Regression: 0.0561 | Decoder: 0.0671\n","Validation: Full loss: 0.1232 | Regression: 0.1000 | Decoder: 0.0720\n","\n","Epoch 54 | Duration 7.33 sec\n","Train:      Full loss: 0.0867 | Regression: 0.0558 | Decoder: 0.0664\n","Validation: Full loss: 0.1176 | Regression: 0.0936 | Decoder: 0.0713\n","\n","Epoch 56 | Duration 7.19 sec\n","Train:      Full loss: 0.0858 | Regression: 0.0553 | Decoder: 0.0656\n","Validation: Full loss: 0.1245 | Regression: 0.1028 | Decoder: 0.0702\n","\n","Epoch 58 | Duration 7.23 sec\n","Train:      Full loss: 0.0847 | Regression: 0.0541 | Decoder: 0.0651\n","Validation: Full loss: 0.1193 | Regression: 0.0971 | Decoder: 0.0694\n","\n","Epoch 60 | Duration 7.28 sec\n","Train:      Full loss: 0.0946 | Regression: 0.0568 | Decoder: 0.0757\n","Validation: Full loss: 0.1282 | Regression: 0.1078 | Decoder: 0.0694\n","Saved model checkpoint to model_epoch_60.pt\n","\n","Epoch 62 | Duration 7.18 sec\n","Train:      Full loss: 0.0832 | Regression: 0.0540 | Decoder: 0.0633\n","Validation: Full loss: 0.1162 | Regression: 0.0938 | Decoder: 0.0686\n","\n","Epoch 64 | Duration 7.30 sec\n","Train:      Full loss: 0.0832 | Regression: 0.0539 | Decoder: 0.0633\n","Validation: Full loss: 0.1209 | Regression: 0.1005 | Decoder: 0.0673\n","\n","Epoch 66 | Duration 7.20 sec\n","Train:      Full loss: 0.0824 | Regression: 0.0533 | Decoder: 0.0628\n","Validation: Full loss: 0.1166 | Regression: 0.0920 | Decoder: 0.0716\n","\n","Epoch 68 | Duration 7.32 sec\n","Train:      Full loss: 0.0815 | Regression: 0.0522 | Decoder: 0.0626\n","Validation: Full loss: 0.1169 | Regression: 0.0959 | Decoder: 0.0668\n","\n","Epoch 70 | Duration 7.22 sec\n","Train:      Full loss: 54.8627 | Regression: 0.1604 | Decoder: 54.8625\n","Validation: Full loss: 0.6570 | Regression: 0.1840 | Decoder: 0.6307\n","Saved model checkpoint to model_epoch_70.pt\n","\n","Epoch 72 | Duration 7.17 sec\n","Train:      Full loss: 0.3198 | Regression: 0.1294 | Decoder: 0.2925\n","Validation: Full loss: 0.3052 | Regression: 0.1708 | Decoder: 0.2530\n","\n","Epoch 74 | Duration 7.22 sec\n","Train:      Full loss: 0.2369 | Regression: 0.1062 | Decoder: 0.2118\n","Validation: Full loss: 0.2530 | Regression: 0.1449 | Decoder: 0.2074\n","\n","Epoch 76 | Duration 7.29 sec\n","Train:      Full loss: 0.2168 | Regression: 0.0947 | Decoder: 0.1950\n","Validation: Full loss: 0.2395 | Regression: 0.1399 | Decoder: 0.1944\n","\n","Epoch 78 | Duration 7.22 sec\n","Train:      Full loss: 0.2092 | Regression: 0.0904 | Decoder: 0.1887\n","Validation: Full loss: 0.2294 | Regression: 0.1306 | Decoder: 0.1885\n","\n","Epoch 80 | Duration 7.20 sec\n","Train:      Full loss: 0.2012 | Regression: 0.0819 | Decoder: 0.1838\n","Validation: Full loss: 0.2221 | Regression: 0.1219 | Decoder: 0.1857\n","Saved model checkpoint to model_epoch_80.pt\n","\n","Epoch 82 | Duration 7.20 sec\n","Train:      Full loss: 0.1957 | Regression: 0.0776 | Decoder: 0.1797\n","Validation: Full loss: 0.2322 | Regression: 0.1277 | Decoder: 0.1940\n","\n","Epoch 84 | Duration 7.22 sec\n","Train:      Full loss: 0.1908 | Regression: 0.0725 | Decoder: 0.1765\n","Validation: Full loss: 0.3808 | Regression: 0.1459 | Decoder: 0.3518\n","\n","Epoch 86 | Duration 7.30 sec\n","Train:      Full loss: 0.1870 | Regression: 0.0701 | Decoder: 0.1734\n","Validation: Full loss: 0.8607 | Regression: 0.1098 | Decoder: 0.8536\n","\n","Epoch 88 | Duration 7.24 sec\n","Train:      Full loss: 0.1830 | Regression: 0.0668 | Decoder: 0.1703\n","Validation: Full loss: 1.3427 | Regression: 0.1303 | Decoder: 1.3364\n","\n","Epoch 90 | Duration 7.15 sec\n","Train:      Full loss: 0.1778 | Regression: 0.0643 | Decoder: 0.1657\n","Validation: Full loss: 1.7273 | Regression: 0.1209 | Decoder: 1.7231\n","Saved model checkpoint to model_epoch_90.pt\n","\n","Epoch 92 | Duration 7.32 sec\n","Train:      Full loss: 0.2283 | Regression: 0.0632 | Decoder: 0.2193\n","Validation: Full loss: 0.5491 | Regression: 0.1231 | Decoder: 0.5351\n","\n","Epoch 94 | Duration 7.29 sec\n","Train:      Full loss: 0.1735 | Regression: 0.0620 | Decoder: 0.1621\n","Validation: Full loss: 0.5920 | Regression: 0.1225 | Decoder: 0.5792\n","\n","Epoch 96 | Duration 7.44 sec\n","Train:      Full loss: 0.1659 | Regression: 0.0600 | Decoder: 0.1547\n","Validation: Full loss: 0.9749 | Regression: 0.1145 | Decoder: 0.9682\n","\n","Epoch 98 | Duration 7.20 sec\n","Train:      Full loss: 0.1609 | Regression: 0.0603 | Decoder: 0.1492\n","Validation: Full loss: 0.9516 | Regression: 0.1166 | Decoder: 0.9444\n","\n","Epoch 100 | Duration 7.27 sec\n","Train:      Full loss: 0.1557 | Regression: 0.0585 | Decoder: 0.1443\n","Validation: Full loss: 0.2331 | Regression: 0.1020 | Decoder: 0.2096\n","Saved model checkpoint to model_epoch_100.pt\n","\n","Lowess validation loss: 0.1042 in Round 67\n"]}]},{"cell_type":"code","source":["#Lowess validation loss: 0.1195 (80/20)\n","#Lowess validation loss: 0.1042 (90/10)\n","!cp model_best.pt drive/MyDrive/model_best_edr_1.pt"],"metadata":{"id":"k5zDxTZ5vLdh","executionInfo":{"status":"ok","timestamp":1652866349185,"user_tz":-120,"elapsed":299,"user":{"displayName":"Moin_Meister","userId":"16105956636675639827"}}},"execution_count":14,"outputs":[]}]}