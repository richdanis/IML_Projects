{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5PGB3crk2Y2R"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from numpy import random as ran\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from PIL import Image\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "471Q_xkLb_1c"
   },
   "outputs": [],
   "source": [
    "# fix seeds\n",
    "torch.manual_seed(13)\n",
    "random.seed(13)\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nV66SUmQDiOU"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFEFab-Z2RKZ",
    "outputId": "6de36dc2-5120-4742-fa12-3b9de73428bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount drive to access data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-bB1gnUa2LTC"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('drive/MyDrive/Data.zip','r') as zipObj:\n",
    "  zipObj.extractall('.')\n",
    "\n",
    "with ZipFile('drive/MyDrive/tensorset_covnext_block5.zip','r') as zipObj:\n",
    "  zipObj.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bvyP37wEyKZN"
   },
   "outputs": [],
   "source": [
    "# dataset to load the feature tensors (storing them as numpy arrays takes much less memory)\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = 'tensorset/' + str(self.data[idx][0]) + '.npy'\n",
    "        im1 = np.load(filename)\n",
    "        filename = 'tensorset/' + str(self.data[idx][1]) + '.npy'\n",
    "        im2 = np.load(filename)\n",
    "        filename = 'tensorset/' + str(self.data[idx][2]) + '.npy'\n",
    "        im3 = np.load(filename)\n",
    "\n",
    "        im1 = torch.from_numpy(im1)\n",
    "        im2 = torch.from_numpy(im2)\n",
    "        im3 = torch.from_numpy(im3)\n",
    "\n",
    "        return im1,im2,im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AFIlCRLV2BOe"
   },
   "outputs": [],
   "source": [
    "# loading pretrained model and selecting the blocks used for training\n",
    "\n",
    "model = models.convnext_tiny(pretrained=True)\n",
    "model.features = nn.Sequential(*[model.features[i] for i in range(6,8)])\n",
    "model.classifier = nn.Sequential(*[model.classifier[i] for i in range(2)])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YmLrj9b0toOz"
   },
   "outputs": [],
   "source": [
    "fname = 'Data/'\n",
    "food = fname + 'food/'\n",
    "train = np.loadtxt(fname + \"train_triplets.txt\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aD5R_0y2QDxe",
    "outputId": "8df827ca-cbfb-4181-ce89-c6efe958e6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplets in train_set:  20181\n",
      "Triplets in val_set:  1652\n",
      "Discarded triplets:  37682\n"
     ]
    }
   ],
   "source": [
    "# create set of training triplets and set of validation triplets,\n",
    "# such that both sets do not share any images\n",
    "# goal: get a precise validation score\n",
    "\n",
    "unique_images_train = set()\n",
    "for i in range(train.shape[0]):\n",
    "    for j in range(train.shape[1]):\n",
    "        unique_images_train.add(train[i][j])\n",
    "\n",
    "k = random.sample(unique_images_train, 1500)\n",
    "train_triplets = list()\n",
    "val_triplets = list()\n",
    "\n",
    "for i in train:\n",
    "    if (i[0] not in k) and (i[1] not in k) and (i[2] not in k): \n",
    "        train_triplets.append(i)\n",
    "    elif (i[0] in k) and (i[1] in k) and (i[2] in k):\n",
    "        val_triplets.append(i)\n",
    "\n",
    "print(\"Triplets in train_set: \",len(train_triplets))\n",
    "print(\"Triplets in val_set: \",len(val_triplets))\n",
    "print(\"Discarded triplets: \",train.shape[0]-len(train_triplets)-len(val_triplets))\n",
    "\n",
    "train = np.array(train_triplets)\n",
    "val = np.array(val_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fy5lwaNNAF45"
   },
   "outputs": [],
   "source": [
    "# triplet loss with cosine similarity as distance function\n",
    "\n",
    "loss_fn = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - nn.functional.cosine_similarity(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "y7L-FKASd56X"
   },
   "outputs": [],
   "source": [
    "# create datasets and dataloader\n",
    "\n",
    "train_dataset = ImgDataset(train)\n",
    "val_dataset = ImgDataset(val)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "valloader = DataLoader(val_dataset, batch_size=16,\n",
    "                        shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "V3ipsr8a_mvg"
   },
   "outputs": [],
   "source": [
    "# define utility functions to compute classification accuracy and\n",
    "# perform evaluation / testing\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "def accuracy(x,y,z):\n",
    "    dist1 = cos(x,y)\n",
    "    dist2 = cos(x,z)\n",
    "    res = torch.gt(dist1,dist2)\n",
    "    return torch.sum(res) / x.shape[0]\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> torch.Tensor:\n",
    "    # goes through the test dataset and computes the validation accuracy\n",
    "    model.eval()  # bring the model into eval mode\n",
    "    with torch.no_grad():\n",
    "        acc_cum = 0.0\n",
    "        num_eval_samples = 0\n",
    "        for x_batch, y_batch, z_batch in valloader:\n",
    "\n",
    "            # move data to GPU\n",
    "            x_batch, y_batch, z_batch = x_batch.to(device), y_batch.to(device), z_batch.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            x = model(x_batch)\n",
    "            y = model(y_batch)\n",
    "            z = model(z_batch)\n",
    "\n",
    "            # calculate accuracy\n",
    "            batch_size = x_batch.shape[0]\n",
    "            num_eval_samples += batch_size\n",
    "            acc_cum += accuracy(x,y,z) * batch_size\n",
    "          \n",
    "        avg_acc = acc_cum / num_eval_samples\n",
    "        avg_acc = torch.tensor(avg_acc)\n",
    "        return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEu7ng1V2T9D",
    "outputId": "8ede1ea1-ef69-4985-9688-289e7911710c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss: 1263.7588 |  Train accuracy: 0.6962 | Test accuracy: 0.7125 | Duration 47.51 sec\n",
      "Epoch 1 | Train loss: 1046.9452 |  Train accuracy: 0.7344 | Test accuracy: 0.7167 | Duration 44.54 sec\n",
      "Epoch 2 | Train loss: 1006.9693 |  Train accuracy: 0.7431 | Test accuracy: 0.7161 | Duration 44.44 sec\n",
      "Saved model checkpoint to model_epoch_2.pt\n",
      "Epoch 3 | Train loss: 971.3525 |  Train accuracy: 0.7550 | Test accuracy: 0.7143 | Duration 44.42 sec\n",
      "Saved model checkpoint to model_epoch_3.pt\n",
      "Epoch 4 | Train loss: 979.2999 |  Train accuracy: 0.7519 | Test accuracy: 0.7258 | Duration 44.42 sec\n",
      "Saved model checkpoint to model_epoch_4.pt\n",
      "Epoch 5 | Train loss: 941.6495 |  Train accuracy: 0.7575 | Test accuracy: 0.7282 | Duration 44.44 sec\n",
      "Saved model checkpoint to model_epoch_5.pt\n",
      "Epoch 6 | Train loss: 930.0148 |  Train accuracy: 0.7731 | Test accuracy: 0.7306 | Duration 44.48 sec\n",
      "Saved model checkpoint to model_epoch_6.pt\n",
      "Epoch 7 | Train loss: 951.3055 |  Train accuracy: 0.7781 | Test accuracy: 0.7191 | Duration 44.54 sec\n",
      "Epoch 8 | Train loss: 898.0140 |  Train accuracy: 0.7856 | Test accuracy: 0.7167 | Duration 44.49 sec\n",
      "Saved model checkpoint to model_epoch_8.pt\n",
      "Epoch 9 | Train loss: 865.6332 |  Train accuracy: 0.8000 | Test accuracy: 0.7234 | Duration 44.46 sec\n",
      "Saved model checkpoint to model_epoch_9.pt\n"
     ]
    }
   ],
   "source": [
    "# Setup the optimizer (adaptive learning rate method)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    # reset statistics trackers\n",
    "    train_loss_cum = 0.0\n",
    "    acc_cum = 0.0\n",
    "    num_samples_epoch = 0\n",
    "    t = time.time()\n",
    "    # Go once through the training dataset (-> epoch)\n",
    "    count = 0\n",
    "    for x_batch,y_batch,z_batch in trainloader:\n",
    "        # zero grads and put model into train mode\n",
    "        optim.zero_grad()\n",
    "        model.train()\n",
    "\n",
    "        # move data to GPU\n",
    "        x_batch, y_batch, z_batch = x_batch.to(device), y_batch.to(device), z_batch.to(device)\n",
    "    \n",
    "        # forward pass\n",
    "        x = model(x_batch)\n",
    "        y = model(y_batch)\n",
    "        z = model(z_batch)\n",
    "        \n",
    "        # loss\n",
    "        loss = loss_fn(x, y, z)\n",
    "        \n",
    "        # backward pass and gradient step\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # keep track of train stats\n",
    "        num_samples_batch = x_batch.shape[0]\n",
    "        num_samples_epoch += num_samples_batch\n",
    "        train_loss_cum += loss * num_samples_batch\n",
    "        \n",
    "        acc_cum += accuracy(x,y,z) * num_samples_batch\n",
    "\n",
    "        # end epoch after 100 batches\n",
    "        count += 1\n",
    "        if count == 100:\n",
    "            break\n",
    "\n",
    "    # average the accumulated statistics\n",
    "    avg_train_loss = train_loss_cum / num_samples_epoch\n",
    "    avg_acc = acc_cum / num_samples_epoch\n",
    "    test_acc = evaluate(model)\n",
    "    epoch_duration = time.time() - t\n",
    "\n",
    "    # print some infos\n",
    "    print(f'Epoch {epoch} | Train loss: {train_loss_cum:.4f} | '\n",
    "          f' Train accuracy: {avg_acc:.4f} | Test accuracy: {test_acc.item():.4f} |'\n",
    "          f' Duration {epoch_duration:.2f} sec')\n",
    "\n",
    "    # save checkpoint of model\n",
    "    if (epoch % 5 == 0 or epoch % 4 == 0 or epoch % 3 == 0 or epoch % 2 == 0) and epoch > 0:\n",
    "        save_path = f'model_epoch_{epoch}.pt'\n",
    "        torch.save(model,\n",
    "                   save_path)\n",
    "        print(f'Saved model checkpoint to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DVqhWNU3UlLr"
   },
   "outputs": [],
   "source": [
    "# store best performing epoch in drive\n",
    "!cp \"model_epoch_5.pt\" \"drive/My Drive/covnext_epoch_5.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0-aQ7jtspzl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
