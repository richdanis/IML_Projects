{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y_5rA_etaYA4"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from numpy import random as ran\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D03RVLR0acgo"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3427kUP3af6E",
    "outputId": "cd0357c7-69a5-470f-cfa5-1069bfd15380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount drive to access data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I-1Q-sRxajMb"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('drive/MyDrive/Data.zip','r') as zipObj:\n",
    "  zipObj.extractall('.')\n",
    "\n",
    "with ZipFile('drive/MyDrive/tensorset_covnext_block5.zip','r') as zipObj:\n",
    "  zipObj.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RoM0BseFawXd"
   },
   "outputs": [],
   "source": [
    "# dataset to load the feature tensors (storing them as numpy arrays takes much less memory)\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = 'tensorset/' + str(self.data[idx][0]) + '.npy'\n",
    "        im1 = np.load(filename)\n",
    "        filename = 'tensorset/' + str(self.data[idx][1]) + '.npy'\n",
    "        im2 = np.load(filename)\n",
    "        filename = 'tensorset/' + str(self.data[idx][2]) + '.npy'\n",
    "        im3 = np.load(filename)\n",
    "\n",
    "        im1 = torch.from_numpy(im1)\n",
    "        im2 = torch.from_numpy(im2)\n",
    "        im3 = torch.from_numpy(im3)\n",
    "\n",
    "        return im1,im2,im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5itCNE9-bFqF",
    "outputId": "c7d8334c-d15f-4edd-fd1d-7f2509816265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU()\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU()\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU()\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "\n",
    "model = torch.load(\"drive/MyDrive/covnext_epoch_5.pt\")\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.avgpool.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PhX1jcgdbNhc"
   },
   "outputs": [],
   "source": [
    "# create test_dataset and dataloader\n",
    "\n",
    "fname = 'Data/'\n",
    "food = fname + 'food/'\n",
    "test = np.loadtxt(fname + \"test_triplets.txt\", dtype=str)\n",
    "\n",
    "test_dataset = ImgDataset(test)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=16,\n",
    "                        shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xCm2g2jqxRyp"
   },
   "outputs": [],
   "source": [
    "# CosineSimilarity is the criterion used to decide if the second or the third\n",
    "# is more similar to the first image\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "def compare(x,y,z):\n",
    "    t = time.time()\n",
    "    pred = np.zeros((x.shape[0],),dtype=int)\n",
    "    dist1 = cos(x,y)\n",
    "    dist2 = cos(x,z)\n",
    "    res = torch.gt(dist1,dist2)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5KpPs59bhiV",
    "outputId": "6f029138-ca9e-4b3c-d68a-f328eb3502a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step:  2000\n"
     ]
    }
   ],
   "source": [
    "# compute the predictions\n",
    "\n",
    "output = torch.empty((0,), dtype=torch.bool).to(device)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for x_batch,y_batch,z_batch in testloader:\n",
    "    with torch.no_grad():\n",
    "      x_batch, y_batch, z_batch = x_batch.to(device), y_batch.to(device), z_batch.to(device)\n",
    "      x = model(x_batch)\n",
    "      y = model(y_batch)\n",
    "      z = model(z_batch)\n",
    "      res = compare(x,y,z)\n",
    "      output = torch.cat((output,res))\n",
    "      count += 1\n",
    "      if count % 2000 == 0:\n",
    "        print(\"Current step: \", count)\n",
    "\n",
    "output = output.cpu().detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XgMauh4nchqK"
   },
   "outputs": [],
   "source": [
    "np.savetxt('convnext_trip_5.txt',output,fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6ZAXE8JbOLdq"
   },
   "outputs": [],
   "source": [
    "!cp \"convnext_trip_5.txt\" \"drive/MyDrive/convnext_trip_5.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY60hzIjnjSx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
